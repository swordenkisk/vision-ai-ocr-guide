{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Vision AI OCR — Interactive Tutorial\n",
    "\n",
    "This notebook walks through the complete Vision AI OCR pipeline step by step.\n",
    "Run each cell in order to understand the core concepts and see live output.\n",
    "\n",
    "**Prerequisites**\n",
    "- A GCP project with the Vision API enabled\n",
    "- `GOOGLE_APPLICATION_CREDENTIALS` set to your service account key path\n",
    "- `pip install -r ../requirements.txt` already run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Environment Setup"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(Path('..').resolve()))\n",
    "\n",
    "# Verify credentials\n",
    "creds_path = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', '')\n",
    "if not creds_path or not Path(creds_path).exists():\n",
    "    print('⚠️  GOOGLE_APPLICATION_CREDENTIALS not set or file not found.')\n",
    "    print('    Set it with: export GOOGLE_APPLICATION_CREDENTIALS=/path/to/key.json')\n",
    "else:\n",
    "    print(f'✅ Credentials found: {creds_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. Single Image Extraction"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ocr import DocumentExtractor\n",
    "\n",
    "extractor = DocumentExtractor()\n",
    "\n",
    "# Replace with your own image path\n",
    "IMAGE_PATH = '../samples/invoice.jpg'\n",
    "\n",
    "if not Path(IMAGE_PATH).exists():\n",
    "    print(f'Sample file not found: {IMAGE_PATH}')\n",
    "    print('Please add a test image to the samples/ directory.')\n",
    "else:\n",
    "    result = extractor.extract(IMAGE_PATH, language='en')\n",
    "\n",
    "    print('=== Extracted Text ===')\n",
    "    print(result['text'][:500])\n",
    "    print(f'\\nWord count : {result[\"word_count\"]}')\n",
    "    print(f'Confidence : {result[\"confidence\"]}')\n",
    "    print(f'\\nFirst 5 bounding boxes:')\n",
    "    for box in result['bounding_boxes'][:5]:\n",
    "        print(f'  \"{box[\"text\"]}\" @ {box[\"vertices\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. Document Text Detection (Dense Documents)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(IMAGE_PATH).exists():\n",
    "    doc_result = extractor.extract_document(IMAGE_PATH, language='en')\n",
    "\n",
    "    print(f'Pages detected : {doc_result[\"page_count\"]}')\n",
    "    print(f'\\nPage metadata:')\n",
    "    for i, page in enumerate(doc_result['pages'], 1):\n",
    "        print(f'  Page {i}: {page[\"width\"]}x{page[\"height\"]}px, '\n",
    "              f'{page[\"block_count\"]} blocks, '\n",
    "              f'confidence={page[\"confidence\"]:.2%}')\n",
    "\n",
    "    print(f'\\nFirst 300 chars:')\n",
    "    print(doc_result['text'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. Handwriting Recognition"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.handwriting import HandwritingExtractor\n",
    "\n",
    "HANDWRITING_PATH = '../samples/handwriting.jpg'\n",
    "\n",
    "if not Path(HANDWRITING_PATH).exists():\n",
    "    print(f'Add a handwriting sample to: {HANDWRITING_PATH}')\n",
    "else:\n",
    "    hw_extractor = HandwritingExtractor()\n",
    "    hw_result = hw_extractor.extract(HANDWRITING_PATH, language_hints=['en'])\n",
    "\n",
    "    print('=== Handwriting Extraction ===')\n",
    "    print(hw_result['text'])\n",
    "    print(f'\\nDetected language : {hw_result[\"detected_language\"]}')\n",
    "    print(f'Average confidence: {hw_result[\"average_confidence\"]:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. Layout Analysis"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.layout_analyzer import LayoutAnalyzer\n",
    "import json\n",
    "\n",
    "if Path(IMAGE_PATH).exists():\n",
    "    analyzer = LayoutAnalyzer()\n",
    "    layout = analyzer.analyze(IMAGE_PATH)\n",
    "\n",
    "    print(f'Page size   : {layout.page_width} x {layout.page_height} px')\n",
    "    print(f'Block count : {len(layout.blocks)}')\n",
    "\n",
    "    columns = analyzer.detect_columns(layout)\n",
    "    print(f'Columns     : {len(columns)}')\n",
    "\n",
    "    print('\\n=== Reading Order (first 10 blocks) ===')\n",
    "    for i, snippet in enumerate(layout.reading_order[:10], 1):\n",
    "        print(f'  {i:>2}. {snippet[:80]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6. Batch Processing"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.batch_processor import BatchProcessor\n",
    "\n",
    "INPUT_DIR  = '../samples'\n",
    "OUTPUT_DIR = '../results/tutorial'\n",
    "\n",
    "processor = BatchProcessor(max_workers=4)\n",
    "report = processor.process_directory(INPUT_DIR, OUTPUT_DIR)\n",
    "\n",
    "print(f'Processed : {report[\"total\"]} file(s)')\n",
    "print(f'Succeeded : {len(report[\"successful\"])}')\n",
    "print(f'Failed    : {len(report[\"failed\"])}')\n",
    "\n",
    "if report['failed']:\n",
    "    print('\\nFailed files:')\n",
    "    for f in report['failed']:\n",
    "        print(f'  {f[\"file\"]}: {f[\"error\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7. Visualise Bounding Boxes"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_bounding_boxes(image_path: str, result: dict, max_boxes: int = 30):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for box in result['bounding_boxes'][:max_boxes]:\n",
    "        vertices = box['vertices']\n",
    "        if len(vertices) == 4:\n",
    "            polygon = [(v[0], v[1]) for v in vertices]\n",
    "            draw.polygon(polygon, outline='red')\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Bounding Boxes (first {max_boxes} words)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if Path(IMAGE_PATH).exists():\n",
    "    result = extractor.extract(IMAGE_PATH)\n",
    "    draw_bounding_boxes(IMAGE_PATH, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "- **GCS Integration**: See `integrations/gcs_loader.py` to process documents directly from Cloud Storage\n",
    "- **BigQuery Export**: See `integrations/bigquery_export.py` to stream results to a data warehouse\n",
    "- **Document AI**: See `integrations/document_ai_bridge.py` for structured form/invoice parsing\n",
    "- **Deployment**: See `infrastructure/` for Docker, Cloud Run, and Terraform configurations\n",
    "- **Cost Optimisation**: See `docs/pricing_optimization.md` for strategies to reduce API spend\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
